Question 1

Step 1: simpledb.Parser.main() and simpledb.Parser.start()

simpledb.Parser.main() is the entry point for the SimpleDB system. It calls simpledb.Parser.start(). The latter performs three main actions:
- It populates the SimpleDB catalog from the catalog text file provided by the user as argument (Database.getCatalog().loadSchema(argv[0]);).
- For each table defined in the system catalog, it computes statistics over the data in the table by calling: TableStats.computeStatistics(), which then does: TableStats s = new TableStats(tableid, IOCOSTPERPAGE);
- It processes the statements submitted by the user (processNextStatement(new ByteArrayInputStream(statementBytes));)

Step 2: simpledb.Parser.processNextStatement()

This method takes two key actions:
- First, it gets a physical plan for the query by invoking handleQueryStatement((ZQuery)s);
- Then it executes the query by calling query.execute();

Step 3: simpledb.Parser.handleQueryStatement()

- This method first calls parseQueryLogicalPlan(tId, (ZQuery)s) to get the logical plan for the query. 
- Then, it tries to get a physical plan from the logical plan by calling LogicalPlan.physicalPlan(tId, TableStats.getStatsMap(), explain). If there exists a physical plan, then it invokes OperatorCardinality.updateOperatorCardinality

Step 4: simpledb.Parser.parseQueryLogicalPlan()

- First, walks through tables in the FROM clause if they exist, adding each as a scan to the logical plan.
- Second, parses the WHERE clause by calling processExpression()
- Third, checks for GROUP BY fields, at most one is present
- Fourth, walks through SELECT list, picks out aggregates, and checks for query validity. If aggregates are valid, they're added to the logical plan
- Fifth, sorts the data, getting ORDER BY if exists. 

Step 5: simpledb.Parser.processExpression()

- simpledb.Parser.processExpression() processes the WHERE clauses of the query, creating filter/join nodes if necessary. If there are nested subqueries, it process the subqueries as regular queries. Filter/join nodes are added to the logical plan if they exist.

Step 6: simpledb.LogicalPlan.physicalPlan()

simpledb.LogicalPlan.physicalPlan() converts the logical plan into a physical plan by returning a DbIterator representing the plan.
- First, it loops through all the tables represented in the query and sets default selectivity of 1.0, e.g. a full table scan, for each.
- Second, for each filter in the query, it determines the affected fields and updates the selectivity for that field's TableStats by calling s.estimateSelectivity(subplan.getTupleDesc().fieldNameToIndex(lf.fieldQuantifiedName), lf.p, f);
- Third, it finds the optimal join orders by calling JoinOptimizer.orderJoins(statsMap,filterSelectivities,explain).
- Fourth, using this order, it carries out the join operation which results in a DbIterator of joined tuples.
- Finally, it goes through the select fields to figure out which fields to include in the final projection, taking into account aggregates and sorting order.

Step 7: simpledb.TableStats.estimateSelectivity()

- This method figures out the type of the predicate field, and calls the corresponding histogram function to estimate the selectivity of the predicate on that field.
- It calls either IntHistogram.estimateSelectivity(op, val) or StringHistogram.estimateSelectivity(op, val).

Step 8: simpledb.IntHistogram.estimateSelectivity() or simpledb.StringHistogram.estimateSelectivity()

- This method takes the predicate and the field and returns an estimate of the fraction of elements within the tuples of the table that are needed to determine the answer to the operation.

Step 9: simpledb.JoinOptimizer.orderJoins()

This method computes and returns the best order of joins that results in the most optimal plan.
- It computes subsets of size starting from 1 to joins.size() and loops through each subset. Within each subset, it loops through each node and computes the best way to join the node with the rest of the subset by calling computeCostAndCardOfSubplan(stats, filterSelectivities, node, subset, best.cost, pc);
- For each iterated node, it checks the cost and if its the cheapest join so far, it records the information in the PlanCache for subsets of its size + 1 to easily reference in its computation.

Step 10: simpledb.JoinOptimizer.computeCostAndCardOfSubplan()

This method computes the cheapest way to join a node and the rest of the subset it belongs to, or null if no such linear joining is possible or cheaper than the best it has found.
- This method first computes the table costs and cardinalities for the two tables that are to be joined when compared to the best ordering so far.
- It then finds the join cost for both the current ordering and swapped table ordering by calling estimateJoinCost(j, t1card, t2card, t1cost, t2cost) and estimateJoinCost(j2, t1card, t2card, t1cost, t2cost) and selects the lower cost one.
- Finally, if the join cost is the best one it has found so far, it records the cardinality of the resulting join by calling estimateJoinCardinality(j, t1card, t2card, leftPkey, rightPkey, stats), the cost and plan in a CostCard object, then returned.

Step 11: simpledb.JoinOptimizer.estimateJoinCost()

This function simply calculates the estimated cost of a join between the two tables given each table's scan cost and cardinality.
- In this project, the estimate comes from adding the IO cost of the nested loops join and an additional CPU cost for processing each tuple.

Step 12: simpledb.JoinOptimizer.estimateJoinCardinality()

This function estimates the number of tuples produced by joining the two tables, given the individual table cardinalities and whether fields are primary/unique keys.
- For equality join operations, it simply returns the larger cardinality.
- For ranged join operations, it uses the heuristic of returning the number which is 30% of the number of tuples produced by the cross-product of the two tables.


Question 6.1

The query plan our optimizer selected (for the 1% dataset) is:
                           π(d.fname,d.lname),card:29729
                            |
                           ⨝(a.id=c.pid),card:29729
  __________________________|___________________________
  |                                                    |
 σ(a.lname=Spicer),card:1                            ⨝(m.mid=c.mid),card:29729      
  |                                    ________________|_________________
 σ(a.fname=John),card:1               |                                |
  |                                   ⨝(d.id=m.did),card:2791         |
  |                           _________|_________                       |
  |                           |                 |                     scan(Casts c)
scan(Actor a)               scan(Director d)  scan(Movie_Director m)

The associated costs are:

Join m:d (Cost =2603000.0, card = 2597)
  Join c:m (Cost =2603000.0, card = 29729)
    Join a:c (Cost =2603000.0, card = 29729)
      a (Cost = 2603000.0, card = 0)
      c (Cost = 1026000.0, card = 29729)
    m (Cost = 6000.0, card = 2791)
  d (Cost = 174000.0, card = 2597)


The orderJoins returns the plan with the best cost, which is computed in the helper function, computeCostandCardOfSubplan. This plan that the orderJoin returns makes sense because joining Director with Movie_Director first is smart since these two tables are smaller than the Casts and Actor tables since there are less directors than actors, thus the joining of two fully scanned tables is not as costly. Naturally, the resulting table has reduced cardinality, which makes it more efficient to now join it with the full scanned Casts table. On the other hand, filtering out the Actor table by first selecting records with the name John Spicer reduces the table to only one record and now joining it with the resulting Director/Casts table keeps the cardinality stable and most efficient.


Question 6.2

We chose to run the following query:

  select m.name 
  from Casts c, Movie m, Genre g 
  where c.mid=m.id and g.mid=m.id 
  and g.genre='Comedy' and m.year=2000;

The query plan our optimizer selected (for the 1% dataset) is:
                                   π(m.name),card:29729
                                    |
                                   ⨝(m.id=c.mid),card:29729
                ____________________|____________________
                |                                       |
               ⨝(g.mid=m.id),card:1                   |
  ______________|______________                         |
  |                           |                         |
 σ(g.genre=Comedy),card:1   σ(m.year=2000),card:63    |
  |                           |                       scan(Casts c)
scan(Genre g)               scan(Movie m)

The associated costs are:

Join g:m (Cost =150000.0, card = 0)
    g (Cost = 150000.0, card = 0)
  Join c:m (Cost =6.5541198E7, card = 62)
    c (Cost = 1026000.0, card = 29729)
    m (Cost = 86000.0, card = 62)

The orderJoins returns the plan with the best cost here as well, again computed in computeCostandCardOfSubplan. This plan makes sense because it quickly filters the Genre and Movie tables before any joins to reduce their cardinality as much as possible. Only the Casts table is left to be joined unfiltered at the end since it does not have any possible filtering.

Discuss and justify any changes you made to the API.

We only added one method, StringHistogram.getNumTups(), to get the number of tuples. Otherwise no changes were made.

Describe any missing or incomplete elements of your code.

We don't have any missing or incomplete elements of our code, in terms of methods that needed implementation for project 3.

Describe how long you spent on the project, and whether there was anything you found particularly difficult or confusing.

The project took a few days to complete. The amount of detail we had to go into for answering questions 1 and 6 was particularly confusing, since it wasn't clear how thorough our responses were supposed to be.

